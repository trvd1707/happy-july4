"use strict";
var __extends = (this && this.__extends) || function (d, b) {
    for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];
    function __() { this.constructor = d; }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
};
var Recognizer_1 = require('./Recognizer');
/**
 * Detects the ID of the speaker. Should be used in parallel with a
 * {CloudRecognizer} for text-independent speaker ID, as shown in the following example:
 * ```
 * let action = asr.createAudioAction();
 * let cloud = new asr.CloudRecognizer();
 * let speaker = new asr.SpeakerRecognizer();
 * let task = cloud + " | " + speaker;
 * action.start(task);
 * ```
 * Alternately, `SpeakerRecognizer`  can be used alone in the case of a text-dependent recognition. For text dependent recognition, Jibo will listen for
 * the words "hey jibo". You can use it in sequence with a {CloudRecognizer}, as shown in the following example:
 * ```
 * let action = asr.createAudioAction();
 * let cloud = new asr.CloudRecognizer();
 * let speaker = new asr.SpeakerRecognizer();
 * let task = speaker + " * " + cloud;
 * action.start(task);
 * ```
 * @class SpeakerRecognizer
 * @private
 * @extends {Recognizer}
 * @memberof module:jibo.services.asr
 * @param {Object} options
 * @param {boolean} options.authenticate_td Uses the text-dependent speaker ID recognizer to listen for "hey jibo".
 * @param {boolean} options.authenticate_ti Uses the text-independent speaker ID recognizer.
 */
var SpeakerRecognizer = (function (_super) {
    __extends(SpeakerRecognizer, _super);
    function SpeakerRecognizer(options) {
        if (options === void 0) { options = {}; }
        if (options.enrollTD) {
            options.path = 'sensory_spkr_enroll_td';
        }
        else if (options.enrollTI) {
            options.path = 'sensory_spkr_enroll_ti';
        }
        else if (options.authTD) {
            options.path = 'sensory_spkr_id_td';
        }
        else if (options.authTI) {
            options.path = 'sensory_spkr_id_ti';
        }
        options.name = "Speaker Enroll TD";
        _super.call(this, options);
    }
    SpeakerRecognizer.prototype.toString = function () {
        return this.pack();
    };
    // special pack function
    // used so that audio tail can be sent.
    // audio tail uses audio from previous recognizer (like hey jibo)
    // to act as the audio for this task.
    // used in both TD and TI.
    SpeakerRecognizer.prototype.pack = function () {
        var body = {
            name: this.name,
            path: this.path,
            bargein: this.bargein,
            nbest: this.nbest,
            timeout: this.timeout,
            speaker_name: this.speakerName,
            incremental: this.incremental,
            audio_tail_length: 1
        };
        body = JSON.stringify(body);
        return body;
    };
    SpeakerRecognizer.prototype.onResult = function (data) {
        var speaker_ids = {
            speakerIds: data.speaker_ids,
            speakerIdStatus: data.speaker_idstatus
        };
        this.emit('result', speaker_ids);
    };
    return SpeakerRecognizer;
}(Recognizer_1.default));
Object.defineProperty(exports, "__esModule", { value: true });
exports.default = SpeakerRecognizer;

//# sourceMappingURL=../../map/services/asr/SpeakerRecognizer.js.map
