{"version":3,"sources":["services/asr/SpeakerRecognizer.js"],"names":[],"mappings":";;;;;;AAAA,2BAAuB,cAAc,CAAC,CAAA;AAEtC;;;;;;;;;;;;;;;;;;;;;;;;;;GA0BG;AACH;IAAgC,qCAAU;IACtC,2BAAY,OAAU;QAAV,uBAAU,GAAV,YAAU;QAClB,EAAE,CAAA,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC;YAClB,OAAO,CAAC,IAAI,GAAI,wBAAwB,CAAC;QAC7C,CAAC;QACD,IAAI,CAAC,EAAE,CAAC,CAAC,OAAO,CAAC,QAAQ,CAAC,CAAC,CAAC;YACxB,OAAO,CAAC,IAAI,GAAG,wBAAwB,CAAC;QAC5C,CAAC;QACD,IAAI,CAAC,EAAE,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC;YACtB,OAAO,CAAC,IAAI,GAAG,oBAAoB,CAAC;QACxC,CAAC;QACD,IAAI,CAAC,EAAE,CAAC,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC;YACtB,OAAO,CAAC,IAAI,GAAG,oBAAoB,CAAC;QACxC,CAAC;QACD,OAAO,CAAC,IAAI,GAAG,mBAAmB,CAAC;QACnC,kBAAM,OAAO,CAAC,CAAC;IACnB,CAAC;IAED,oCAAQ,GAAR;QACI,MAAM,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC;IACvB,CAAC;IAED,wBAAwB;IACxB,uCAAuC;IACvC,iEAAiE;IACjE,qCAAqC;IACrC,0BAA0B;IAC1B,gCAAI,GAAJ;QACI,IAAI,IAAI,GAAG;YACP,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,YAAY,EAAE,IAAI,CAAC,WAAW;YAC9B,WAAW,EAAE,IAAI,CAAC,WAAW;YAC7B,iBAAiB,EAAE,CAAC;SACvB,CAAC;QACF,IAAI,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;QAC5B,MAAM,CAAC,IAAI,CAAC;IAChB,CAAC;IAED,oCAAQ,GAAR,UAAS,IAAI;QACT,IAAI,WAAW,GAAG;YACd,UAAU,EAAE,IAAI,CAAC,WAAW;YAC5B,eAAe,EAAE,IAAI,CAAC,gBAAgB;SACzC,CAAC;QACF,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,WAAW,CAAC,CAAC;IACrC,CAAC;IACL,wBAAC;AAAD,CAjDA,AAiDC,CAjD+B,oBAAU,GAiDzC;AAED;kBAAe,iBAAiB,CAAC","file":"services/asr/SpeakerRecognizer.js","sourcesContent":["import Recognizer from './Recognizer';\n\n/**\n * Detects the ID of the speaker. Should be used in parallel with a\n * {CloudRecognizer} for text-independent speaker ID, as shown in the following example:\n * ```\n * let action = asr.createAudioAction();\n * let cloud = new asr.CloudRecognizer();\n * let speaker = new asr.SpeakerRecognizer();\n * let task = cloud + \" | \" + speaker;\n * action.start(task);\n * ```\n * Alternately, `SpeakerRecognizer`  can be used alone in the case of a text-dependent recognition. For text dependent recognition, Jibo will listen for\n * the words \"hey jibo\". You can use it in sequence with a {CloudRecognizer}, as shown in the following example:\n * ```\n * let action = asr.createAudioAction();\n * let cloud = new asr.CloudRecognizer();\n * let speaker = new asr.SpeakerRecognizer();\n * let task = speaker + \" * \" + cloud;\n * action.start(task);\n * ```\n * @class SpeakerRecognizer\n * @private\n * @extends {Recognizer}\n * @memberof module:jibo.services.asr\n * @param {Object} options\n * @param {boolean} options.authenticate_td Uses the text-dependent speaker ID recognizer to listen for \"hey jibo\".\n * @param {boolean} options.authenticate_ti Uses the text-independent speaker ID recognizer.\n */\nclass SpeakerRecognizer extends Recognizer {\n    constructor(options={}) {\n        if(options.enrollTD) {\n            options.path =  'sensory_spkr_enroll_td';\n        }\n        else if (options.enrollTI) {\n            options.path = 'sensory_spkr_enroll_ti';\n        }\n        else if (options.authTD) {\n            options.path = 'sensory_spkr_id_td';\n        }\n        else if (options.authTI) {\n            options.path = 'sensory_spkr_id_ti';\n        }\n        options.name = \"Speaker Enroll TD\";\n        super(options);\n    }\n\n    toString() {\n        return this.pack();\n    }\n\n    // special pack function\n    // used so that audio tail can be sent.\n    // audio tail uses audio from previous recognizer (like hey jibo)\n    // to act as the audio for this task.\n    // used in both TD and TI.\n    pack() {\n        let body = {\n            name: this.name,\n            path: this.path,\n            bargein: this.bargein,\n            nbest: this.nbest,\n            timeout: this.timeout,\n            speaker_name: this.speakerName,\n            incremental: this.incremental,\n            audio_tail_length: 1\n        };\n        body = JSON.stringify(body);\n        return body;\n    }\n\n    onResult(data) {\n        let speaker_ids = {\n            speakerIds: data.speaker_ids, \n            speakerIdStatus: data.speaker_idstatus\n        };\n        this.emit('result', speaker_ids);\n    }\n}\n\nexport default SpeakerRecognizer;\n"],"sourceRoot":"/source/"}